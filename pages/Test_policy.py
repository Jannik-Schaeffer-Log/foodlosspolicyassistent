########################################
# Import libraries
########################################
import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
from scipy import stats
from sklearn.linear_model import LinearRegression
from factor_analyzer import FactorAnalyzer
from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity
from factor_analyzer.factor_analyzer import calculate_kmo
from factor_analyzer import (ConfirmatoryFactorAnalyzer, ModelSpecificationParser)

import scipy.stats

########################################
# Configure Page
########################################
st.set_page_config(page_title="Country Food Loss Policy Assistant", page_icon="ðŸ¥‘",layout="wide")

########################################
# Add Title
########################################
st.header("Country Food Loss Policy Assistant")
st.sidebar.header("Country Food Loss Policy Assistant")
########################################
# Read Data
########################################
# LPI Data
df_LPI= pd.read_csv("data/LPI_Data.csv", encoding='latin-1')
# FAO Data
df_FAO = pd.read_csv("data/Data.csv")
# Country Categories by Worldbank 
country_categories_tidy= pd.read_csv('data/country_categories_tidy.csv', delimiter=';')
# Commodity Groups by FAO 
commodity_groups_tidy= pd.read_csv('data/commodity_groups.csv', delimiter=';')
# LPI Country Name Changes
df_LPI_new_country_names= pd.read_csv("data/LPI_Countries_name_changes.csv", delimiter=';')
# FAO Country Name Changes
df_FAO_new_country_names= pd.read_csv("data/FAO_Countries_name_changes.csv", delimiter=';')
# FAO Country Name Changes
df_policies= pd.read_csv("data/All_Food_Loss_Policies.csv", delimiter=';')

########################################
# Clean Data 
# Change Data Types
########################################
# Drop duplicates & name change
df=df_FAO.drop_duplicates()

#get loss-percentage in range 0-100
with st.expander('See loss_percentage plot'):
    st.write(df['loss_percentage'].max() , df['loss_percentage'].min(),df['loss_percentage'].mean() )
    data_swarmplot = df['loss_percentage']
    fig_swarm = px.box(data_swarmplot, y='loss_percentage')
    st.plotly_chart(fig_swarm, use_container_width=True)

#drop food supply stages which aren't relevant for food loss
food_supply_stages=[
    'Whole supply chain',
    'Storage',
    'Processing',
    'Trader',
    'Wholesale',
    'Post-harvest',
    'Transport',
    'Export',
    '<NA>',
    'Distribution',
    'Market',
    'Stacking',
    'Grading',
    'Packing'
    ]

#st.write(df['food_supply_stage'].unique())
df=df[df['food_supply_stage'].isin(food_supply_stages)]


#change country names
df["country"]=df["country"].replace(to_replace="United Republic of Tanzania",value=str("Tanzania"))
df["country"]=df["country"].replace(to_replace='Democratic Republic of the Congo',value=str('Congo, Dem. Rep.'))
df["country"]=df["country"].replace(to_replace='Iran (Islamic Republic of)',value=str('Iran'))
df["country"]=df["country"].replace(to_replace='Bolivia (Plurinational State of)',value=str('Bolivia'))
df["country"]=df["country"].replace(to_replace='Viet Nam',value=str('Vietnam'))
df["country"]=df["country"].replace(to_replace='China,Taiwan',value=str('Taiwan'))
df["country"]=df["country"].replace(to_replace="Democratic People's Republic of Korea",value=str("Korea, South"))
df["country"]=df["country"].replace(to_replace='Republic of Korea',value=str("Korea, North"))
df["country"]=df["country"].replace(to_replace="Lao People's Democratic Republic",value=str('Laos'))
df["country"]=df["country"].replace(to_replace="Venezuela (Bolivarian Republic of)",value=str('Venezuela'))
df["country"]=df["country"].replace(to_replace='The former Yugoslav Republic of Macedonia',value=str('North Macedonia'))

# Drop unwanted Region data
df=df[df["country"]!='Australia and New Zealand']
df=df[df["country"]!='Africa']
df=df[df["country"]!='Europe']
df=df[df["country"]!='Latin America and the Caribbean']
df=df[df["country"]!='Northern Africa']
df=df[df["country"]!='Northern America']
df=df[df["country"]!='South-Eastern Asia']
df=df[df["country"]!='Southern Asia']
df=df[df["country"]!='Sub-Saharan Africa']
df=df[df["country"]!='Sub-Saharan Africa']
df=df[df["country"]!='United Kingdom of Great Britain and Northern Ireland']
df=df[df["country"]!='Western Africa']
df=df[df["country"]!='Western Asia']

#change name Back
df_FAO=df

#align country names for later merge
def Change_Country_Names( df_new_names,column_new_names ,df_to_change,column_name):
    name_dict=df_new_names.set_index(column_new_names).T.to_dict('list')
    df_to_change[column_name]=df_to_change[column_name].map(name_dict)
    df_to_change[column_name]=df_to_change[column_name].str.get(0)

Change_Country_Names(df_LPI_new_country_names,'LPI Countries',df_LPI, 'Country Name' )
#Change_Country_Names(df_FAO_new_country_names,'FAO Countries',df_FAO, 'country' )

# select columns from LPI-data
df_LPI_reg=df_LPI[["Country Name","Series Name","2007 [YR2007]","2010 [YR2010]","2012 [YR2012]","2014 [YR2014]","2016 [YR2016]","2018 [YR2018]"]]

# rename columns
df_LPI_reg.columns=["Country Name","Series Name","2007","2010","2012","2014","2016","2018"]

# select only score data from LPI
df_LPI_reg=df_LPI_reg[df_LPI_reg["Series Name"].str.contains('score',na=False)]
df_LPI_reg=df_LPI_reg.dropna()
# build dataframe for regression wit LPI-data
df_LPI_reg = df_LPI_reg.pivot(index="Country Name",columns='Series Name', values=["2007","2010","2012","2014","2016","2018"])
y=[]
years=["2007","2010","2012","2014","2016","2018"]
x=df_LPI_reg[years[0]]
x['year']=years[0]
y=x
for i in range(1,len(years)):
    x=df_LPI_reg[years[i]]
    x['year']=years[i]
    y=y.append(x)

y=y.sort_values(['Country Name','year'])
# changing datatype
y['year']=y['year'].astype('int64')


# prepare FAO Data for merge
df_FAO_pivot=pd.pivot_table(df_FAO,index=['country','year','commodity','food_supply_stage'], values='loss_percentage',aggfunc=np.mean, fill_value=None)
df_FAO_pivot=df_FAO_pivot.reset_index()

# merge filtered data of both data source
df_reg=pd.merge(y,df_FAO_pivot,how='inner', left_on=['Country Name','year'],right_on=['country','year'])
df_reg=df_reg.replace("..",np.NaN)

## Add Country Categories to the Dataframe
df_reg=pd.merge(df_reg,country_categories_tidy, how='inner', left_on='country', right_on='Country')
df_reg=df_reg.drop(columns=['Country'])
df_reg=df_reg.ffill(axis = 0)

## Add Commodity-Groups to the Dataframe
df_reg=pd.merge(df_reg,commodity_groups_tidy, how='inner', left_on='commodity', right_on='Commodities')
df_reg=df_reg.drop(columns=['Commodities'])
df_reg=df_reg.ffill(axis = 0)

##Add missing years to Dataframe
df_reg['year']=pd.to_datetime(df_reg['year'],format='%Y')
df_reg = df_reg.set_index('year')
country_list=df_reg['country'].unique()
df_reg_extended=pd.DataFrame()
for i in range(len(country_list)):
    test=df_reg[df_reg['country']==country_list[i]].resample('Y').last()
    df_reg_extended=df_reg_extended.append(test)
df_reg_extended=df_reg_extended.ffill(axis = 0)

#Add Year Column again
df_reg=df_reg_extended.reset_index()
df_reg['year']=df_reg['year'].astype('string')
df_reg['year']=df_reg['year'].apply(lambda x: x[0:4])
df_reg['year']=df_reg['year'].astype('int')

#Remerge foodloss_percentage
df_reg=df_reg.drop(columns=['loss_percentage'])
df_reg=pd.merge(df_reg,df_FAO_pivot,how='inner', left_on=['country','year','commodity','food_supply_stage'],right_on=['country','year','commodity','food_supply_stage'])
df_reg=df_reg.set_index('year')
df_reg=df_reg.drop(columns=['commodity'])

dict_income_group={
    'UPPER-MIDDLE-INCOME ECONOMIES ($4,256 TO $13,205)':'Upper-Middle-Income Economies',
    'LOW-INCOME ECONOMIES ($1,085 OR LESS)Â ':'Low-Income Economies',
    'LOWER-MIDDLE INCOME ECONOMIES ($1,086 TO $4,255)':'Lower-Middle Income Economies',
    'HIGH-INCOME ECONOMIES ($13,205 OR MORE)Â ':'High-Income Economies'
}

df_reg['Income']=df_reg['Income'].replace(dict_income_group)

# select Country
selected_country=st.selectbox('Select country',options=df_reg['country'].unique())

# filter df for dependent Income-Group
selected_income_group=df_reg[df_reg['country']==selected_country]['Income'].unique()
selected_income_group=str(selected_income_group)[2:-2]

# filter df for dependent Region
selected_region=df_reg[df_reg['country']==selected_country]['Region'].unique()
selected_region=str(selected_region)[2:-2]

#select Series
dict_series={
    'Ability to track and trace consignments, score (1=low to 5=high)':0,
    'Competence and quality of logistics services, score (1=low to 5=high)':1,
    'Ease of arranging competitively priced international shipments, score (1=low to 5=high)':2,
    'Efficiency of the clearance process, score (1=low to 5=high)':3,
    'Frequency with which shipments reach consignee within scheduled or expected time, score (1=low to 5=high)':4,
    'Logistics performance index: Overall score (1=low to 5=high)':5,
    'Logistics performance index: Overall score (1=low to 5=high), lower bound':6,
    'Logistics performance index: Overall score (1=low to 5=high), upper bound':7,
    'Quality of trade- and transport-related infrastructure, score (1=low to 5=high)':8,
}

########################################
# Correlation Test
########################################

with st.expander('Correlation of LPI-categories and Food Loss'):
    #prepare arrays for correlation test
    cor_array_x= np.array(df_reg['loss_percentage'].astype(float))
    cor_array_y_1= np.array(df_reg['Ability to track and trace consignments, score (1=low to 5=high)'].astype(float))
    cor_array_y_2= np.array(df_reg['Competence and quality of logistics services, score (1=low to 5=high)'].astype(float))
    cor_array_y_3= np.array(df_reg['Ease of arranging competitively priced international shipments, score (1=low to 5=high)'].astype(float))
    cor_array_y_4= np.array(df_reg['Efficiency of the clearance process, score (1=low to 5=high)'].astype(float))
    cor_array_y_5= np.array(df_reg['Frequency with which shipments reach consignee within scheduled or expected time, score (1=low to 5=high)'].astype(float))
    cor_array_y_6= np.array(df_reg['Quality of trade- and transport-related infrastructure, score (1=low to 5=high)'].astype(float))
    
    #Correlation Test
    r_1,p_1 = scipy.stats.pearsonr(cor_array_x, cor_array_y_1)
    r_2,p_2 = scipy.stats.pearsonr(cor_array_x, cor_array_y_2)
    r_3,p_3 = scipy.stats.pearsonr(cor_array_x, cor_array_y_3)
    r_4,p_4 = scipy.stats.pearsonr(cor_array_x, cor_array_y_4)
    r_5,p_5 = scipy.stats.pearsonr(cor_array_x, cor_array_y_5)
    r_6,p_6 = scipy.stats.pearsonr(cor_array_x, cor_array_y_6)
    corr_dict={"Pearson's r":[r_1,r_2,r_3,r_4,r_5,r_6,],'p-value':[p_1,p_2,p_3,p_4,p_5,p_6]}
    corr_index_names=['Tracking and Tracing', 'Quality of log services','Ease of arranging shipments','Customs','Timeliness','Infrastructure' ]
    cor_df=pd.DataFrame(data=corr_dict, index=corr_index_names)

    st.write('Correlation between Food Loss percentages and LPI Categories for all datapoints.')
    st.write(cor_df)


########################################
# Regression
########################################

#### Prepare Data for Income Goup Regressions
def Income_group_data(Income_Group):
    df_income_group=df_reg[df_reg['Income']==f'{Income_Group}']
    return df_income_group



def build_model(model_data):
    X=model_data.drop([
        "loss_percentage",
        'country',
        'Logistics performance index: Overall score (1=low to 5=high)',
        "Logistics performance index: Overall score (1=low to 5=high), lower bound",
        "Logistics performance index: Overall score (1=low to 5=high), upper bound",
        'Region',
        'Income',
        'Commodity Groups',
        'food_supply_stage'
        ], axis=1).values
    y=model_data["loss_percentage"]

    names=model_data.drop([
        "loss_percentage",
        'country',
        'Logistics performance index: Overall score (1=low to 5=high)',
        "Logistics performance index: Overall score (1=low to 5=high), lower bound",
        "Logistics performance index: Overall score (1=low to 5=high), upper bound",
        'Region',
        'Income',
        'Commodity Groups',
        'food_supply_stage'
        ], axis=1).columns

    reg = LinearRegression()
    Regression_model=reg.fit(X,y)


    #print(Regression_model.intercept_)
    global df_reg_values
    df_reg_values=pd.DataFrame(list(Regression_model.coef_))
    df_reg_values.index=names

LPI_cat_names=[
    'Ability to track and trace consignments, score (1=low to 5=high)',
    'Competence and quality of logistics services, score (1=low to 5=high)',
    'Ease of arranging competitively priced international shipments, score (1=low to 5=high)',
    'Efficiency of the clearance process, score (1=low to 5=high)',
    'Frequency with which shipments reach consignee within scheduled or expected time, score (1=low to 5=high)',
    'Quality of trade- and transport-related infrastructure, score (1=low to 5=high)'
]

Income_Groups=[
    'Low-Income Economies',
    'Lower-Middle Income Economies',
    'Upper-Middle-Income Economies',
    'High-Income Economies'
    ]

df_reg_income_total=pd.DataFrame()
df_reg_income_total.index=LPI_cat_names
for i in range(len(Income_Groups)):
    reg_data=Income_group_data(Income_Groups[i])
    build_model(reg_data)
    df_reg_values.columns=[Income_Groups[i]]
    df_reg_income_total=df_reg_income_total.join(df_reg_values)
# st.write('Datatable with Regression Coef. per Income Group:')
# st.dataframe(df_reg_income_total)

build_model(df_reg[df_reg['country']==selected_country])
df_reg_country=pd.DataFrame()
df_reg_country.index=LPI_cat_names
df_reg_country=df_reg_country.join(df_reg_values)
df_reg_country.columns=[f'{selected_country}']
# st.write('country regression')
# st.dataframe(df_reg_country)

df_for_Means=df_reg
LPI_cat=[
    'Ability to track and trace consignments, score (1=low to 5=high)',
    'Competence and quality of logistics services, score (1=low to 5=high)',
    'Ease of arranging competitively priced international shipments, score (1=low to 5=high)',
    'Efficiency of the clearance process, score (1=low to 5=high)',
    'Frequency with which shipments reach consignee within scheduled or expected time, score (1=low to 5=high)',
    'Quality of trade- and transport-related infrastructure, score (1=low to 5=high)'
    ]

for i in [0,1,2,3,4,6,7,8,14]:
    df_for_Means.iloc[:,i]=pd.to_numeric(df_for_Means.iloc[:,i])
for i in [9,10,11,12,13]:
    df_for_Means.iloc[:,i]=df_for_Means.iloc[:,i].astype("category")

Income_mean=pd.pivot_table(df_reg,index=['Income'], values=LPI_cat,aggfunc=np.mean, fill_value=None)
Income_mean=Income_mean.drop(index=['Nan'])
# st.write('Mean per Income Group')
# st.dataframe(Income_mean)


df_selected_country=df_for_Means[df_for_Means['country']==selected_country]
Country_mean=pd.pivot_table(df_selected_country,index=['country'], values=LPI_cat,aggfunc=np.mean, fill_value=None)
# st.write('Mean of Country')
# st.dataframe(Country_mean)

# st.write('Diff. of Means (Country & Income Groups)')
Diff_Mean_Income= Income_mean.sub(Country_mean.iloc[0, :])
Diff_Mean_Income['Abs_Sum_Mean_Diff']= abs(Diff_Mean_Income.sum(axis = 1))
Diff_Mean_Income=Diff_Mean_Income.sort_values('Abs_Sum_Mean_Diff', ascending=True)
# st.dataframe(Diff_Mean_Income)


dict_comparison={'Actual Group': [df_selected_country['Income'].value_counts().idxmax()],'Nearest Group': [Diff_Mean_Income.index[0]]}#,df_selected_country['Region'].value_counts().idxmax(),df_selected_country['Commodity Groups'].value_counts().idxmax(),df_selected_country['food_supply_stage'].value_counts().idxmax()], 'Nearest Group': [Diff_Mean_Income.index[0],Diff_Mean_Region.index[0],Diff_Mean_Commodity_group.index[0],Diff_Mean_Supply_stage.index[0]]}
df_comparison=pd.DataFrame(dict_comparison)
df_comparison.index=['Income Group']#, 'Region', 'Commodity Group', 'Food Supply Stage']
df_comparison['is_equal']=(df_comparison['Nearest Group']==df_comparison['Actual Group'])
# st.write('Is Actual Income Group in LPI-Categories also the closest?')
# st.dataframe(df_comparison)


with st.expander('Details Regression'):
    st.write('Datatable with Regression Coef. per Income Group:')
    st.dataframe(df_reg_income_total)

    st.write('country regression')
    st.dataframe(df_reg_country)

with st.expander('Details Mean Comparison'):
    st.write('Mean per Income Group')
    st.dataframe(Income_mean)

    st.write('Mean of Country')
    st.dataframe(Country_mean)

    st.write('Diff. of Means (Country & Income Groups)')
    st.dataframe(Diff_Mean_Income)

    st.write('Is Actual Income Group in LPI-Categories also the closest?')
    st.dataframe(df_comparison)

################
#TEST STATISTICS
################
# st.write('Tests')

def perform_Normalitytest(country,actual_income_group, nearest_income_group):
    pval=0.05
    #Country
    df_normality_test_country=pd.DataFrame()
    df_normality_test_country.index=['statistic','pval']
    for i in range(len(LPI_cat)): 
        df_normality_test_country_LPI_cat=pd.DataFrame(stats.shapiro(df_reg[df_reg['country']==country][LPI_cat[i]]))
        df_normality_test_country_LPI_cat.index=['statistic','pval']
        df_normality_test_country_LPI_cat.columns=[f'{LPI_cat[i]}']
        df_normality_test_country=df_normality_test_country.join(df_normality_test_country_LPI_cat,lsuffix='_Country', rsuffix='_Income_group')
    df_normality_test_country=df_normality_test_country.transpose() 
    df_normality_test_country['Normality_check']=(df_normality_test_country['pval']>=pval)

    #Actual Income Group
    df_normality_test_actual_income=pd.DataFrame()
    df_normality_test_actual_income.index=['statistic','pval']
    for i in range(len(LPI_cat)): 
        df_normality_test_actual_income_LPI_cat=pd.DataFrame(stats.shapiro(df_reg[df_reg['Income']==actual_income_group][LPI_cat[i]]))
        df_normality_test_actual_income_LPI_cat.index=['statistic','pval']
        df_normality_test_actual_income_LPI_cat.columns=[f'{LPI_cat[i]}']
        df_normality_test_actual_income=df_normality_test_actual_income.join(df_normality_test_actual_income_LPI_cat,lsuffix='_Country', rsuffix='_Income_group')
    df_normality_test_actual_income=df_normality_test_actual_income.transpose() 
    df_normality_test_actual_income['Normality_check']=(df_normality_test_actual_income['pval']>=pval)

    #Nearest Income Group
    df_normality_test_nearest_income=pd.DataFrame()
    df_normality_test_nearest_income.index=['statistic','pval']
    for i in range(len(LPI_cat)): 
        df_normality_test_nearest_income_LPI_cat=pd.DataFrame(stats.shapiro(df_reg[df_reg['Income']==nearest_income_group][LPI_cat[i]]))
        df_normality_test_nearest_income_LPI_cat.index=['statistic','pval']
        df_normality_test_nearest_income_LPI_cat.columns=[f'{LPI_cat[i]}']
        df_normality_test_nearest_income=df_normality_test_nearest_income.join(df_normality_test_nearest_income_LPI_cat,lsuffix='_Country', rsuffix='_Income_group')
    df_normality_test_nearest_income=df_normality_test_nearest_income.transpose() 
    df_normality_test_nearest_income['Normality_check']=(df_normality_test_nearest_income['pval']>=pval)

    return df_normality_test_country,df_normality_test_actual_income, df_normality_test_nearest_income
   
try:
    df_normality_test_country, df_normality_test_actual_income, df_normality_test_nearest_income =perform_Normalitytest(selected_country, selected_income_group,df_comparison.iloc[0,1])
except:
    df_normality_test_country=[]
    df_normality_test_actual_income=[]
    df_normality_test_nearest_income=[]
    st.info(f'{selected_country} does not have sufficient datapoints to run the model properly.')
# st.write('Normality Test Country')
# st.dataframe(df_normality_test_country)
# st.write('Normality Test Actual Income Group')
# st.dataframe(df_normality_test_actual_income)
# st.write('Normality Test Nearest Income Group')
# st.dataframe(df_normality_test_nearest_income)


def perform_Ttest(country,actual_income_group, nearest_income_group):
    pval=0.05
    #Actual_Income & Country
    df_ttest_actual_income=pd.DataFrame()
    df_ttest_actual_income.index=['statistic','pval']
    for i in range(len(LPI_cat)): 
        df_ttest_actual_income_LPI_cat=pd.DataFrame(stats.ttest_ind(df_reg[df_reg['country']==country][LPI_cat[i]],df_reg[df_reg['Income']==actual_income_group][LPI_cat[i]],equal_var=False))
        df_ttest_actual_income_LPI_cat.index=['statistic','pval']
        df_ttest_actual_income_LPI_cat.columns=[f'{LPI_cat[i]}']
        df_ttest_actual_income=df_ttest_actual_income.join(df_ttest_actual_income_LPI_cat,lsuffix='_Country', rsuffix='_Income_group')
    df_ttest_actual_income=df_ttest_actual_income.transpose() 
    df_ttest_actual_income['Ttest_check']=(df_ttest_actual_income['pval']<pval)

    #Nearest_Income & Country
    df_ttest_nearest_income=pd.DataFrame()
    df_ttest_nearest_income.index=['statistic','pval']
    for i in range(len(LPI_cat)): 
        df_ttest_nearest_income_LPI_cat=pd.DataFrame(stats.ttest_ind(df_reg[df_reg['country']==country][LPI_cat[i]],df_reg[df_reg['Income']==nearest_income_group][LPI_cat[i]],equal_var=False))
        df_ttest_nearest_income_LPI_cat.index=['statistic','pval']
        df_ttest_nearest_income_LPI_cat.columns=[f'{LPI_cat[i]}']
        df_ttest_nearest_income=df_ttest_nearest_income.join(df_ttest_nearest_income_LPI_cat,lsuffix='_Country', rsuffix='_Income_group')
    df_ttest_nearest_income=df_ttest_nearest_income.transpose() 
    df_ttest_nearest_income['Ttest_check']=(df_ttest_nearest_income['pval']<pval)
    return df_ttest_actual_income, df_ttest_nearest_income

try:
    df_ttest_actual_income, df_ttest_nearest_income =perform_Ttest(selected_country, selected_income_group,df_comparison.iloc[0,1])
except:
    df_ttest_actual_income=[]
    df_ttest_nearest_income=[]
    st.info(f'{selected_country} does not have sufficient datapoints to run the model properly.')
# st.write('Ttest Actual Income Group')
# st.dataframe(df_ttest_actual_income)
# st.write('Ttest Nearest Income Group')
# st.dataframe(df_ttest_nearest_income)

with st.expander('Details Tests'):
    st.write('Normality Test Country')
    st.dataframe(df_normality_test_country)
    st.write('Normality Test Actual Income Group')
    st.dataframe(df_normality_test_actual_income)
    st.write('Normality Test Nearest Income Group')
    st.dataframe(df_normality_test_nearest_income)
    st.write('Ttest Actual Income Group')
    st.dataframe(df_ttest_actual_income)
    st.write('Ttest Nearest Income Group')
    st.dataframe(df_ttest_nearest_income)



################
#LPI-category Selection
################


Income_group_actual=selected_income_group
nearest_income_group=df_comparison.iloc[0,1]
LPI_cat_order_country=df_reg_country[df_reg_country[f'{selected_country}']<0]


#Auswahl ob Regression country oder Income-group gewÃ¤hlt wird und welche Income Group gewÃ¤hlt wird.
datapoints=len(df_reg[df_reg['country']==selected_country])
if (len(df_reg[df_reg['country']==selected_country])<=5)|(sum(df_reg_country[selected_country])==0):
    if (df_comparison['is_equal'].bool()==True) :
        LPI_cat_order_country=df_reg_income_total[df_reg_income_total[Income_group_actual]<0][Income_group_actual]
        st.info(f'There are only {datapoints} datapoints for {selected_country} so its Income-group:"{Income_group_actual}" was used to determine the policy-areas.')
        if (sum(df_reg_country[selected_country])==0):
            st.info(f'Additional Info: {selected_country}s datapoints were not interpretable for the model, so the Income-group data were used instead.')
    if (df_comparison['is_equal'].bool()==False) & (df_ttest_actual_income['Ttest_check'].sum()>=df_ttest_nearest_income['Ttest_check'].sum()):
        LPI_cat_order_country=df_reg_income_total[df_reg_income_total[nearest_income_group]<0][nearest_income_group]
        st.info(f'There are only {datapoints} datapoints for {selected_country} so its closest Income-group:"{nearest_income_group}" was used to determine the policy-areas. The actual Income-group is: {Income_group_actual}.')
        if (sum(df_reg_country[selected_country])==0):
            st.info(f'Additional Info: {selected_country}s datapoints were not interpretable for the model, so the Income-group data were used instead.')

LPI_cat_order_country=pd.DataFrame(LPI_cat_order_country)
LPI_cat_order_country.columns=[f'{selected_country}']


LPI_cat_order_country=LPI_cat_order_country.sort_values(f'{selected_country}',ascending=False)
LPI_cat_order_country['weight']=np.arange(len(LPI_cat_order_country))+1
LPI_cat_order_country['weight']=pd.to_numeric(LPI_cat_order_country['weight'])
LPI_cat_order_country=LPI_cat_order_country.sort_values(by=['weight'], ascending = False)
LPI_cat_order_country=LPI_cat_order_country.reset_index()
LPI_cat_order_country.columns=['LPI-Category ordered by Priority (highest first)','Regression coefficent', 'Priority']

LPI_cat_name={
    'Ability to track and trace consignments, score (1=low to 5=high)':'Tracking and Tracing',
    'Competence and quality of logistics services, score (1=low to 5=high)':'Quality of log services',
    'Ease of arranging competitively priced international shipments, score (1=low to 5=high)':'Ease of arranging shipments',
    'Efficiency of the clearance process, score (1=low to 5=high)':'Customs',
    'Frequency with which shipments reach consignee within scheduled or expected time, score (1=low to 5=high)':'Timeliness',
    'Quality of trade- and transport-related infrastructure, score (1=low to 5=high)':'Infrastructure'
    }
LPI_cat_order_country=LPI_cat_order_country.replace({'LPI-Category ordered by Priority (highest first)':LPI_cat_name})
with st.expander('Details LPI-categories'):
    st.write('Identified policy areas to reduce Food Loss')
    st.dataframe(LPI_cat_order_country['LPI-Category ordered by Priority (highest first)'])







################
#Factor Analysis
################
data_raw = pd.read_csv('data/CFA_Policies.csv',sep=';')
data=data_raw
LPI_categories=data['LPI-category'].unique()

#Functions to avoid singular matrix error
mu=0.0
std = 0.1
np.random.seed(21389712) #repeatable random number
def gaussian_noise(x):
    noise = np.random.normal(mu, std, size = x.shape)
    x_noisy = x + noise
    return x_noisy 

def make_nonsingular(matrix):
  n = matrix.shape[0]
  m = matrix.shape[1]
  for i in range(n):
    for j in range(m):
      matrix.iloc[i, j] = gaussian_noise(matrix.iloc[i, j])
  return matrix

#function to perform Faktor Analysis

# import semopy
# from semopy import Model

################
#confirmatory Factor analysis
################
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import Normalizer


scale1= MinMaxScaler()
scale2= StandardScaler()
scale3=Normalizer()
# standardization of dependent variables

data= data.iloc[:,[2,3,4,5,6]]
data= data.T
data=make_nonsingular(data)
st.write(data)
data= scale1.fit_transform(data)
st.write(data)
# data=make_nonsingular(data)
# st.write(data)
# data= scale1.fit_transform(data)
# st.write(data)
model_dict = {"F1": [0,1,2,3,4,5,6,7],
              "F2": [8,9,10],
              "F3": [11,12,13,14,15,16],
              "F4": [17,18,19,20,21,22,23,24],
              "F5": [25,26,27,28,29,30],
              "F6": [31]}
model_spec = ModelSpecificationParser.parse_model_specification_from_dict(data,model_dict)

cfa = ConfirmatoryFactorAnalyzer(model_spec, disp=False)

cfa.fit(data)

st.write(cfa.loadings_)
Factor_loading=pd.DataFrame(cfa.loadings_)
Factor_loading['factor_loadings']=Factor_loading.replace(0,np.nan).max(1)
st.write(Factor_loading)


def factor_analysis(LPI_cat):
    LPI_category_data=data_raw[data_raw['LPI-category']==LPI_cat]
    X=LPI_category_data[['survey_1','survey_2','survey_3','survey_4','survey_5']]
    # Create factor analysis object and perform factor analysis
    # fa = FactorAnalyzer(rotation=None, n_factors=1)

    # #add noise to each value to avoid a singular matrix
    # X=make_nonsingular(X)
    # fa.fit(X)
    with st.expander(f'See the factoranalysis insights of {LPI_cat}'):
        st.write(f"{LPI_cat}: Chi-value, p-value ", calculate_bartlett_sphericity(X))
        st.write(f"{LPI_cat}: Kaiser-Meyer-Olkin criterion per variable, in total ", calculate_kmo(X))

    # model = Model("example_model", manifest_variables=['survey_1','survey_2','survey_3','survey_4','survey_5'], latent_variables=['factor1'], paths=[('factor1', 'survey_1'), ('factor1', 'survey_2'), ('factor1', 'survey_3'),('factor1', 'survey_4'),('factor1', 'survey_5')])
    # fit = model.fit(X)
    # stats = semopy.calc_stats(model)
    # st.write(stats.T)
    #returned are Factor loadings
    #return fa.transform(X)

    # Get results
    # fa.loadings_
    # fa.get_communalities()
    # fa.get_eigenvalues()
    # fa.get_factor_variance()
    # fa.get_uniquenesses()
    return





#run function for each LPI-categorie
#Factor_Loadings=pd.DataFrame()
# for i in range(len(LPI_categories)-1):
#     Factor_Loadings[LPI_categories[i]]=pd.DataFrame(factor_analysis(LPI_categories[i]))
for i in range(len(LPI_categories)-1):
    factor_analysis(LPI_categories[i])

#get tidy data    
# Factor_Loadings=Factor_Loadings.melt(ignore_index=False).dropna()
# Factor_Loadings.columns=['LPI-category', 'factor_loading']

#factor loading for Timeliness is set to 1
#Factor_Loadings=Factor_Loadings.append({'LPI-category': 'Timeliness', 'factor_loading':1}, ignore_index=True)
#data['factor_loading']=Factor_Loadings['factor_loading']
data_raw['factor_loading']=Factor_loading['factor_loadings']
st.write(data_raw)
st.subheader(f'List of policy-measures to reduce Food Loss in {selected_country}')
for i in range(len(LPI_cat_order_country['LPI-Category ordered by Priority (highest first)'])):
    LPI_cat = LPI_cat_order_country['LPI-Category ordered by Priority (highest first)'][i]
    data_LPI_cat = data_raw[data_raw['LPI-category']==LPI_cat]
    data_LPI_cat = pd.DataFrame(data_LPI_cat).sort_values(by=['factor_loading'],ascending=False)
    data_LPI_cat = data_LPI_cat.fillna('not found in literature')
    if i ==0: 
        st.write(f'1st Priority: **{LPI_cat}**.   See its policy-measures (highest priority first) below in order to improve in this area.')
    if i ==1: 
        st.write(f'2nd Priority: **{LPI_cat}**.   See its policy-measures (highest priority first) below in order to improve in this area.')
    if i ==2: 
        st.write(f'3rd Priority: **{LPI_cat}**.   See its policy-measures (highest priority first) below in order to improve in this area.')
    if i ==3: 
        st.write(f'4th Priority: **{LPI_cat}**.   See its policy-measures (highest priority first) below in order to improve in this area.')
    if i ==4: 
        st.write(f'5th Priority: **{LPI_cat}**.   See its policy-measures (highest priority first) below in order to improve in this area.')
    if i ==5: 
        st.write(f'6th Priority: **{LPI_cat}**.   See its policy-measures (highest priority first) below in order to improve in this area.')
    st.write(data_LPI_cat[['Policy','Benefits','Risks']].set_index('Policy'))





















# LPI_cat_order=df_reg_income_total[df_reg_income_total[Income_group_actual]<0][Income_group_actual]
# LPI_cat_order=LPI_cat_order.sort_values(ascending=False)
# LPI_cat_order=pd.DataFrame(LPI_cat_order)
# LPI_cat_order['Weights']=np.arange(len(LPI_cat_order))+1
# LPI_cat_order['Weights']=pd.to_numeric(LPI_cat_order['Weights'])
# LPI_cat_order=LPI_cat_order.reset_index()
# LPI_cat_order.columns=['category','Regression_Coef', 'weight']
# selected_Commodity_Group = df_selected_country['Commodity Groups'].value_counts().idxmax()
# selected_supply_stage = df_selected_country['food_supply_stage'].value_counts().idxmax()
# df_cat_weights=LPI_cat_order[['category','weight']]
# df_cat_weights=df_cat_weights.append(LPI_cat_order_country[['category','weight']])
# df_cat_weights.loc[len(df_cat_weights.index)]=[selected_region, 1]
# df_cat_weights.loc[len(df_cat_weights.index)]=[selected_supply_stage, 1]
# df_cat_weights.loc[len(df_cat_weights.index)]=[selected_Commodity_Group, 1]
# df_cat_weights=df_cat_weights.groupby(['category']).sum()
# df_cat_weights=df_cat_weights.reset_index()
# st.dataframe(df_cat_weights)
# #st.dataframe(df_policies)

# df_policies_test=df_policies
# for i in [0,4,6-38]:
#     df_policies_test.iloc[:,i]=pd.to_numeric(df_policies_test.iloc[:,i])

# for i in range(len(df_cat_weights)):
#     df_policies_test[df_cat_weights.iloc[i,0]]+=df_cat_weights.iloc[i,1]

# df_policies_test=df_policies_test.replace(1,0)
# df_policies_test['Total weight']=df_policies_test.iloc[:,4:38].sum(axis = 1)
# df_policies_test=df_policies_test.sort_values('Total weight', ascending=False)


# df_policy_recommendation=df_policies_test[['Policy Short', 'Policy Component', 'Policy Area', 'Total weight']]
# st.dataframe(df_policy_recommendation)





